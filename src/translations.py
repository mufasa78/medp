"""
Translation dictionary for the Medical Image Super-Resolution application.
Contains translations for English and Chinese.
"""

translations = {
    'en': {
        # Navigation
        'app_title': 'Medical Image Super-Resolution',
        'home': 'Home',
        'technology': 'Technology',
        'about': 'About',

        # Home page
        'tagline': 'Enhance the resolution of medical images using advanced deep learning techniques.',
        'description': 'Upload your medical images and see the enhanced results in real-time. Compare different super-resolution methods and process images in batch.',
        'single_processing': 'Single Image',
        'batch_processing': 'Batch Processing',

        # Model descriptions
        'model_srcnn': 'SRCNN: Fast and lightweight model for basic super-resolution.',
        'model_espcn': 'ESPCN: Efficient model with pixel shuffling for real-time applications.',
        'model_edsr': 'EDSR: Enhanced Deep SR with residual blocks for better detail preservation.',
        'model_rcan': 'RCAN: Advanced model with channel attention for capturing fine details.',
        'model_srresnet': 'SRResNet: Residual network architecture with skip connections.',
        'model_color_srcnn': 'Color SRCNN: SRCNN model adapted for color image processing.',
        'model_color_espcn': 'Color ESPCN: ESPCN model adapted for color image processing.',
        'model_color_edsr': 'Color EDSR: EDSR model adapted for color image processing.',
        'model_color_rcan': 'Color RCAN: RCAN model adapted for color image processing.',
        'model_color_srresnet': 'Color SRResNet: SRResNet model adapted for color image processing.',

        # Upload section
        'upload_image': 'Upload Image',
        'drag_drop': 'Drag & drop your image here or click to browse',
        'processing_options': 'Processing Options',
        'dl_model': 'Deep Learning Model',
        'classical_method': 'Compare with Classical Method',
        'preserve_color': 'Preserve original colors',
        'preserve_color_desc': 'When enabled, the original color information will be preserved in the super-resolved image.',
        'process_image': 'Process Image',
        'processing': 'Processing your image...',

        # Batch processing
        'upload_multiple': 'Upload Multiple Images',
        'drag_drop_multiple': 'Drag & drop multiple images here or click to browse',
        'no_files': 'No files selected',
        'batch_options': 'Batch Processing Options',
        'process_batch': 'Process Batch',

        # Results
        'original_image': 'Original Image',
        'reference_image': 'Reference image for quality metrics',
        'result': 'Result',
        'download': 'Download',
        'processed_images': 'Processed {0} Images',
        'avg_metrics': 'Average Quality Metrics:',

        # Metrics
        'psnr': 'PSNR: {0} dB',
        'psnr_title': 'Peak Signal-to-Noise Ratio (higher is better)',
        'ssim': 'SSIM: {0}',
        'ssim_title': 'Structural Similarity Index (higher is better)',

        # Technology page
        'tech_title': 'Our Technology',
        'tech_subtitle': 'Explore the advanced AI technology behind our medical image super-resolution system',
        'key_features': 'Key Features',
        'deep_learning': 'Deep Learning',
        'deep_learning_desc': 'Utilizes advanced neural networks trained on medical imaging datasets',
        'high_performance': 'High Performance',
        'high_performance_desc': 'Optimized for speed and accuracy with GPU acceleration',
        'accessibility': 'Accessibility',
        'accessibility_desc': 'Web-based interface makes the technology available anywhere',
        'tech_overview': 'Technology Overview',
        'tech_overview_desc': 'Our medical image super-resolution system uses state-of-the-art deep learning techniques to enhance the quality and resolution of medical images. The technology is designed specifically for medical imaging, with a focus on preserving diagnostic features while improving clarity and detail.',
        'image_quality_metrics': 'Image Quality Metrics',
        'models_title': 'Super-Resolution Models',
        'models_desc': 'We implement several state-of-the-art deep learning models for super-resolution:',
        'classical_methods_title': 'Classical Methods',
        'classical_methods_desc': 'In addition to deep learning approaches, we also implement traditional image processing techniques:',
        'training_process': 'Training Process',
        'training_process_desc': 'Our models are trained using a specialized pipeline designed for medical images:',

        # About page
        'about_title': 'About Our Project',
        'about_subtitle': 'Learn about our mission, team, and the story behind our medical image enhancement technology',
        'mission': 'Our Mission',
        'mission_desc': 'Our mission is to improve medical imaging accessibility and quality worldwide through advanced AI technology.',
        'mission_points': 'We aim to:',
        'mission_point1': 'Enhance diagnostic capabilities through improved image resolution',
        'mission_point2': 'Make advanced image processing accessible to medical facilities worldwide',
        'mission_point3': 'Contribute to better patient outcomes through improved imaging technology',
        'mission_belief': 'We believe that by applying cutting-edge AI and deep learning techniques to medical imaging, we can make a significant impact on healthcare quality and accessibility.',
        'project_history': 'Project History',
        'inception': 'Project Inception',
        'inception_desc': 'The project began as a research initiative to explore the application of super-resolution techniques to medical imaging. Initial research focused on evaluating different neural network architectures for image enhancement.',
        'prototype': 'First Prototype',
        'prototype_desc': 'Development of the first SRCNN prototype for medical image enhancement. Early tests showed promising results with X-ray and MRI images.',
        'expansion': 'Model Expansion',
        'expansion_desc': 'Added additional models (EDSR, RCAN) and implemented comparative analysis tools. Began collecting feedback from medical professionals.',
        'web_interface': 'Web Interface',
        'web_interface_desc': 'Developed the web application to make the technology accessible to medical professionals without requiring technical expertise.',
        'testimonials': 'Testimonials',
        'team': 'Our Team',
        'lead_developer': 'Lead Developer',
        'lead_developer_desc': 'Responsible for the core super-resolution algorithms and model architecture design.',
        'ml_engineer': 'ML Engineer',
        'ml_engineer_desc': 'Specializes in training and optimizing deep learning models for medical imaging applications.',
        'medical_advisor': 'Medical Advisor',
        'medical_advisor_desc': 'Provides clinical expertise to ensure the technology meets real-world medical needs.',

        # Technology page specific
        'srcnn_title': 'Super-Resolution Convolutional Neural Network (SRCNN)',
        'srcnn_desc': 'SRCNN is our primary model architecture, designed to efficiently enhance image resolution while preserving important medical details. The network consists of three main components:',
        'srcnn_feature_extraction': 'Feature Extraction: The first layer extracts patches from the low-resolution input and represents them as feature maps.',
        'srcnn_nonlinear_mapping': 'Non-linear Mapping: The middle layer maps these feature representations to high-resolution patch representations.',
        'srcnn_reconstruction': 'Reconstruction: The final layer aggregates the predictions to produce the high-resolution output.',
        'srcnn_diagram': 'SRCNN Architecture Diagram',

        'espcn_title': 'Efficient Sub-Pixel Convolutional Neural Network (ESPCN)',
        'espcn_desc': 'ESPCN is an alternative architecture that uses sub-pixel convolution for efficient upscaling. This model processes the image in the low-resolution space and only upscales at the very end, making it computationally efficient.',
        'espcn_diagram': 'ESPCN Architecture Diagram',

        'edsr_title': 'Enhanced Deep Super-Resolution Network (EDSR)',
        'edsr_desc': 'EDSR is our most advanced model, designed for high-quality super-resolution. It removes unnecessary modules from conventional residual networks and expands the model size while stabilizing the training process.',
        'edsr_diagram': 'EDSR Architecture Diagram',
        'edsr_effective': 'This model is particularly effective for complex medical images where fine details are critical for diagnosis.',

        'psnr_metric': 'PSNR',
        'psnr_metric_desc': 'Peak Signal-to-Noise Ratio measures the ratio between the maximum possible power of a signal and the power of corrupting noise',
        'psnr_formula_desc': 'Where MAX‚ÇÅ is the maximum pixel value (255 for 8-bit images) and MSE is the Mean Squared Error between the original and processed images.',
        'psnr_typical_values': 'Typical values for medical images range from 25-45 dB, with higher values indicating better quality.',

        'ssim_metric': 'SSIM',
        'ssim_metric_desc': 'Structural Similarity Index measures the similarity between two images based on structural information, luminance, and contrast. Values range from -1 to 1, with 1 indicating perfect similarity.',
        'ssim_perception': 'Unlike PSNR, SSIM considers human visual perception, making it more aligned with perceived image quality.',
        'ssim_typical_values': 'For medical images, SSIM values above 0.85 typically indicate good quality preservation.',

        'metrics_auto_calc': 'Our application automatically calculates and displays these metrics for each processed image, allowing you to objectively compare different super-resolution methods.',

        'dataset_title': 'Dataset',
        'dataset_desc': 'The models are trained on a diverse dataset of medical images, including:',
        'dataset_xray': 'X-rays (chest, bone, dental)',
        'dataset_mri': 'MRI scans (brain, spine, joints)',
        'dataset_ct': 'CT scans (various body regions)',
        'dataset_ultrasound': 'Ultrasound images',

        'training_methodology': 'Training Methodology',
        'training_methodology_desc': 'We employ several advanced techniques to optimize model performance:',
        'mixed_precision': 'Mixed Precision Training: Accelerates training while maintaining accuracy',
        'learning_rate': 'Learning Rate Scheduling: Adaptive learning rates for optimal convergence',
        'early_stopping': 'Early Stopping: Prevents overfitting by monitoring validation performance',
        'gradient_clipping': 'Gradient Clipping: Stabilizes training by preventing exploding gradients',
        'data_augmentation': 'Data Augmentation: Enhances model generalization through synthetic variations',

        'clinical_applications': 'Clinical Applications',
        'clinical_applications_desc': 'Our super-resolution technology has several important applications in clinical settings:',
        'legacy_enhancement': 'Legacy Equipment Enhancement',
        'legacy_enhancement_desc': 'Improves the quality of images from older medical imaging equipment, extending their useful life and improving diagnostic capabilities without hardware upgrades.',
        'detail_enhancement': 'Detail Enhancement',
        'detail_enhancement_desc': 'Enhances fine details in medical images that may be critical for accurate diagnosis, such as small lesions, fracture lines, or tissue abnormalities.',
        'archive_restoration': 'Archive Restoration',
        'archive_restoration_desc': 'Enhances the quality of archived medical images that may have degraded over time or were originally captured at lower resolutions.',
        'telemedicine': 'Telemedicine Support',
        'telemedicine_desc': 'Improves the quality of transmitted images in telemedicine applications, ensuring remote specialists can make accurate assessments.',
        'xray_enhancement': 'Example: X-ray Enhancement',
        'original': 'Original',
        'enhanced': 'Enhanced',

        # About page specific
        'ongoing_development': 'Ongoing Development',
        'ongoing_development_desc': 'Continuing to improve model performance, expand supported image types, and enhance the user interface based on user feedback.',
        'january_2023': 'January 2023',
        'march_2023': 'March 2023',
        'june_2023': 'June 2023',
        'october_2023': 'October 2023',
        'january_2024': 'January 2024',
        'present': 'Present',

        'testimonial1': '"This technology has significantly improved our ability to analyze subtle details in older X-ray images. It\'s like getting a hardware upgrade without changing our equipment."',
        'testimonial1_author': '‚Äî Dr. Sarah Johnson, Radiologist',
        'testimonial2': '"We\'ve been using this tool for enhancing ultrasound images, and the results are remarkable. The enhanced clarity helps us make more confident diagnoses, especially in challenging cases."',
        'testimonial2_author': '‚Äî Dr. Michael Chen, Sonographer',
        'testimonial3': '"As a rural healthcare provider with limited resources, this technology has been invaluable. It helps us get more diagnostic value from our existing imaging equipment."',
        'testimonial3_author': '‚Äî Dr. Robert Patel, Rural Health Clinic Director',

        # Footer
        'footer_copyright': '¬© 2025 Medical Super-Resolution Project',
        'footer_powered': 'Powered by PyTorch & Flask',
        'medical_advisor_desc': 'Provides clinical expertise and ensures the technology meets real-world medical needs.'
    },

    'zh': {
        # Navigation
        'app_title': 'ÂåªÂ≠¶ÂõæÂÉèË∂ÖÂàÜËæ®Áéá',
        'home': 'È¶ñÈ°µ',
        'technology': 'ÊäÄÊúØ',
        'about': 'ÂÖ≥‰∫éÊàë‰ª¨',

        # Home page
        'tagline': '‰ΩøÁî®ÂÖàËøõÁöÑÊ∑±Â∫¶Â≠¶‰π†ÊäÄÊúØÊèêÈ´òÂåªÂ≠¶ÂõæÂÉèÁöÑÂàÜËæ®Áéá„ÄÇ',
        'description': '‰∏ä‰º†ÊÇ®ÁöÑÂåªÂ≠¶ÂõæÂÉèÔºåÂÆûÊó∂Êü•ÁúãÂ¢ûÂº∫ÊïàÊûú„ÄÇÊØîËæÉ‰∏çÂêåÁöÑË∂ÖÂàÜËæ®ÁéáÊñπÊ≥ïÔºåÊâπÈáèÂ§ÑÁêÜÂõæÂÉè„ÄÇ',
        'single_processing': 'ÂçïÂº†ÂõæÂÉè',
        'batch_processing': 'ÊâπÈáèÂ§ÑÁêÜ',

        # Model descriptions
        'model_srcnn': 'SRCNN: Áî®‰∫éÂü∫Êú¨Ë∂ÖÂàÜËæ®ÁéáÁöÑÂø´ÈÄüËΩªÈáèÁ∫ßÊ®°Âûã„ÄÇ',
        'model_espcn': 'ESPCN: ‰ΩøÁî®ÂÉèÁ¥†Ê∑∑Ê¥óÁöÑÈ´òÊïàÊ®°ÂûãÔºåÈÄÇÁî®‰∫éÂÆûÊó∂Â∫îÁî®„ÄÇ',
        'model_edsr': 'EDSR: Â¢ûÂº∫ÂûãÊ∑±Â∫¶Ë∂ÖÂàÜËæ®ÁéáÁΩëÁªúÔºåÂÖ∑ÊúâÊÆãÂ∑ÆÂùóÔºåÂèØÊõ¥Â•ΩÂú∞‰øùÁïôÁªÜËäÇ„ÄÇ',
        'model_rcan': 'RCAN: ÂÖ∑ÊúâÈÄöÈÅìÊ≥®ÊÑèÂäõÊú∫Âà∂ÁöÑÈ´òÁ∫ßÊ®°ÂûãÔºåÂèØÊçïËé∑Á≤æÁªÜÁªÜËäÇ„ÄÇ',
        'model_srresnet': 'SRResNet: ÂÖ∑ÊúâË∑≥Ë∑ÉËøûÊé•ÁöÑÊÆãÂ∑ÆÁΩëÁªúÊû∂ÊûÑ„ÄÇ',
        'model_color_srcnn': 'ÂΩ©Ëâ≤SRCNN: ÈÄÇÁî®‰∫éÂΩ©Ëâ≤ÂõæÂÉèÂ§ÑÁêÜÁöÑSRCNNÊ®°Âûã„ÄÇ',
        'model_color_espcn': 'ÂΩ©Ëâ≤ESPCN: ÈÄÇÁî®‰∫éÂΩ©Ëâ≤ÂõæÂÉèÂ§ÑÁêÜÁöÑESPCNÊ®°Âûã„ÄÇ',
        'model_color_edsr': 'ÂΩ©Ëâ≤EDSR: ÈÄÇÁî®‰∫éÂΩ©Ëâ≤ÂõæÂÉèÂ§ÑÁêÜÁöÑEDSRÊ®°Âûã„ÄÇ',
        'model_color_rcan': 'ÂΩ©Ëâ≤RCAN: ÈÄÇÁî®‰∫éÂΩ©Ëâ≤ÂõæÂÉèÂ§ÑÁêÜÁöÑRCANÊ®°Âûã„ÄÇ',
        'model_color_srresnet': 'ÂΩ©Ëâ≤SRResNet: ÈÄÇÁî®‰∫éÂΩ©Ëâ≤ÂõæÂÉèÂ§ÑÁêÜÁöÑSRResNetÊ®°Âûã„ÄÇ',

        # Upload section
        'upload_image': '‰∏ä‰º†ÂõæÂÉè',
        'drag_drop': 'ÊãñÊîæÂõæÂÉèÂà∞Ê≠§Â§ÑÊàñÁÇπÂáªÊµèËßà',
        'processing_options': 'Â§ÑÁêÜÈÄâÈ°π',
        'dl_model': 'Ê∑±Â∫¶Â≠¶‰π†Ê®°Âûã',
        'classical_method': '‰∏é‰º†ÁªüÊñπÊ≥ïÊØîËæÉ',
        'preserve_color': '‰øùÁïôÂéüÂßãÈ¢úËâ≤',
        'preserve_color_desc': 'ÂêØÁî®ÂêéÔºåË∂ÖÂàÜËæ®ÁéáÂõæÂÉè‰∏≠Â∞Ü‰øùÁïôÂéüÂßãÈ¢úËâ≤‰ø°ÊÅØ„ÄÇ',
        'process_image': 'Â§ÑÁêÜÂõæÂÉè',
        'processing': 'Ê≠£Âú®Â§ÑÁêÜÊÇ®ÁöÑÂõæÂÉè...',

        # Batch processing
        'upload_multiple': '‰∏ä‰º†Â§öÂº†ÂõæÂÉè',
        'drag_drop_multiple': 'ÊãñÊîæÂ§öÂº†ÂõæÂÉèÂà∞Ê≠§Â§ÑÊàñÁÇπÂáªÊµèËßà',
        'no_files': 'Êú™ÈÄâÊã©Êñá‰ª∂',
        'batch_options': 'ÊâπÈáèÂ§ÑÁêÜÈÄâÈ°π',
        'process_batch': 'ÊâπÈáèÂ§ÑÁêÜ',

        # Results
        'original_image': 'ÂéüÂßãÂõæÂÉè',
        'reference_image': 'Ë¥®ÈáèÊåáÊ†áÂèÇËÄÉÂõæÂÉè',
        'result': 'ÁªìÊûú',
        'download': '‰∏ãËΩΩ',
        'processed_images': 'Â∑≤Â§ÑÁêÜ {0} Âº†ÂõæÂÉè',
        'avg_metrics': 'Âπ≥ÂùáË¥®ÈáèÊåáÊ†á:',

        # Metrics
        'psnr': 'PSNR: {0} dB',
        'psnr_title': 'Â≥∞ÂÄº‰ø°Âô™ÊØîÔºàË∂äÈ´òË∂äÂ•ΩÔºâ',
        'ssim': 'SSIM: {0}',
        'ssim_title': 'ÁªìÊûÑÁõ∏‰ººÊÄßÊåáÊï∞ÔºàË∂äÈ´òË∂äÂ•ΩÔºâ',

        # Technology page
        'tech_title': 'Êàë‰ª¨ÁöÑÊäÄÊúØ',
        'tech_subtitle': 'Êé¢Á¥¢Êàë‰ª¨ÂåªÂ≠¶ÂõæÂÉèË∂ÖÂàÜËæ®ÁéáÁ≥ªÁªüËÉåÂêéÁöÑÂÖàËøõ‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØ',
        'key_features': '‰∏ªË¶ÅÁâπÁÇπ',
        'deep_learning': 'Ê∑±Â∫¶Â≠¶‰π†',
        'deep_learning_desc': 'Âà©Áî®Âú®ÂåªÂ≠¶ÂΩ±ÂÉèÊï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉÁöÑÂÖàËøõÁ•ûÁªèÁΩëÁªú',
        'high_performance': 'È´òÊÄßËÉΩ',
        'high_performance_desc': 'ÈÄöËøáGPUÂä†ÈÄü‰ºòÂåñÈÄüÂ∫¶ÂíåÂáÜÁ°ÆÊÄß',
        'accessibility': 'Êòì‰∫éËÆøÈóÆ',
        'accessibility_desc': 'Âü∫‰∫éÁΩëÁªúÁöÑÁïåÈù¢‰ΩøÊäÄÊúØÈöèÂ§ÑÂèØÁî®',
        'tech_overview': 'ÊäÄÊúØÊ¶ÇËø∞',
        'tech_overview_desc': 'Êàë‰ª¨ÁöÑÂåªÂ≠¶ÂõæÂÉèË∂ÖÂàÜËæ®ÁéáÁ≥ªÁªü‰ΩøÁî®ÊúÄÂÖàËøõÁöÑÊ∑±Â∫¶Â≠¶‰π†ÊäÄÊúØÊù•ÊèêÈ´òÂåªÂ≠¶ÂõæÂÉèÁöÑË¥®ÈáèÂíåÂàÜËæ®Áéá„ÄÇËØ•ÊäÄÊúØ‰∏ì‰∏∫ÂåªÂ≠¶ÊàêÂÉèËÆæËÆ°ÔºåÈáçÁÇπÊòØÂú®ÊèêÈ´òÊ∏ÖÊô∞Â∫¶ÂíåÁªÜËäÇÁöÑÂêåÊó∂‰øùÁïôËØäÊñ≠ÁâπÂæÅ„ÄÇ',
        'image_quality_metrics': 'ÂõæÂÉèË¥®ÈáèÊåáÊ†á',
        'models_title': 'Ë∂ÖÂàÜËæ®ÁéáÊ®°Âûã',
        'models_desc': 'Êàë‰ª¨ÂÆûÁé∞‰∫ÜÂá†ÁßçÊúÄÂÖàËøõÁöÑÊ∑±Â∫¶Â≠¶‰π†Ë∂ÖÂàÜËæ®ÁéáÊ®°ÂûãÔºö',
        'classical_methods_title': '‰º†ÁªüÊñπÊ≥ï',
        'classical_methods_desc': 'Èô§‰∫ÜÊ∑±Â∫¶Â≠¶‰π†ÊñπÊ≥ïÂ§ñÔºåÊàë‰ª¨ËøòÂÆûÁé∞‰∫Ü‰º†ÁªüÁöÑÂõæÂÉèÂ§ÑÁêÜÊäÄÊúØÔºö',
        'training_process': 'ËÆ≠ÁªÉËøáÁ®ã',
        'training_process_desc': 'Êàë‰ª¨ÁöÑÊ®°Âûã‰ΩøÁî®‰∏ì‰∏∫ÂåªÂ≠¶ÂõæÂÉèËÆæËÆ°ÁöÑ‰∏ìÈó®ÁÆ°ÈÅìËøõË°åËÆ≠ÁªÉÔºö',

        # About page
        'about_title': 'ÂÖ≥‰∫éÊàë‰ª¨ÁöÑÈ°πÁõÆ',
        'about_subtitle': '‰∫ÜËß£Êàë‰ª¨ÁöÑ‰ΩøÂëΩ„ÄÅÂõ¢ÈòüÂíåÂåªÂ≠¶ÂõæÂÉèÂ¢ûÂº∫ÊäÄÊúØËÉåÂêéÁöÑÊïÖ‰∫ã',
        'mission': 'Êàë‰ª¨ÁöÑ‰ΩøÂëΩ',
        'mission_desc': 'Êàë‰ª¨ÁöÑ‰ΩøÂëΩÊòØÈÄöËøáÂÖàËøõÁöÑ‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÊèêÈ´òÂÖ®ÁêÉÂåªÂ≠¶ÊàêÂÉèÁöÑÂèØÂèäÊÄßÂíåË¥®Èáè„ÄÇ',
        'mission_points': 'Êàë‰ª¨ÁöÑÁõÆÊ†áÊòØÔºö',
        'mission_point1': 'ÈÄöËøáÊèêÈ´òÂõæÂÉèÂàÜËæ®ÁéáÂ¢ûÂº∫ËØäÊñ≠ËÉΩÂäõ',
        'mission_point2': '‰ΩøÂÖàËøõÁöÑÂõæÂÉèÂ§ÑÁêÜÊäÄÊúØÂØπÂÖ®ÁêÉÂåªÁñóÊú∫ÊûÑÂèØÂèä',
        'mission_point3': 'ÈÄöËøáÊîπËøõÁöÑÊàêÂÉèÊäÄÊúØ‰øÉËøõÊõ¥Â•ΩÁöÑÊÇ£ËÄÖÁªìÊûú',
        'mission_belief': 'Êàë‰ª¨Áõ∏‰ø°ÔºåÈÄöËøáÂ∞ÜÂâçÊ≤ø‰∫∫Â∑•Êô∫ËÉΩÂíåÊ∑±Â∫¶Â≠¶‰π†ÊäÄÊúØÂ∫îÁî®‰∫éÂåªÂ≠¶ÊàêÂÉèÔºåÊàë‰ª¨ÂèØ‰ª•ÂØπÂåªÁñóË¥®ÈáèÂíåÂèØÂèäÊÄß‰∫ßÁîüÈáçÂ§ßÂΩ±Âìç„ÄÇ',
        'project_history': 'È°πÁõÆÂéÜÂè≤',
        'inception': 'È°πÁõÆÂêØÂä®',
        'inception_desc': 'ËØ•È°πÁõÆÂßã‰∫é‰∏ÄÈ°πÁ†îÁ©∂ËÆ°ÂàíÔºåÊó®Âú®Êé¢Á¥¢Ë∂ÖÂàÜËæ®ÁéáÊäÄÊúØÂú®ÂåªÂ≠¶ÊàêÂÉè‰∏≠ÁöÑÂ∫îÁî®„ÄÇÂàùÊ≠•Á†îÁ©∂ÈõÜ‰∏≠Âú®ËØÑ‰º∞‰∏çÂêåÁöÑÁ•ûÁªèÁΩëÁªúÊû∂ÊûÑ‰ª•Â¢ûÂº∫ÂõæÂÉè„ÄÇ',
        'prototype': 'È¶ñ‰∏™ÂéüÂûã',
        'prototype_desc': 'ÂºÄÂèë‰∫ÜÁ¨¨‰∏Ä‰∏™Áî®‰∫éÂåªÂ≠¶ÂõæÂÉèÂ¢ûÂº∫ÁöÑSRCNNÂéüÂûã„ÄÇÊó©ÊúüÊµãËØïÂú®XÂ∞ÑÁ∫øÂíåMRIÂõæÂÉè‰∏äÊòæÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁªìÊûú„ÄÇ',
        'expansion': 'Ê®°ÂûãÊâ©Â±ï',
        'expansion_desc': 'Ê∑ªÂä†‰∫ÜÈ¢ùÂ§ñÁöÑÊ®°ÂûãÔºàEDSRÔºåRCANÔºâÂπ∂ÂÆûÁé∞‰∫ÜÊØîËæÉÂàÜÊûêÂ∑•ÂÖ∑„ÄÇÂºÄÂßãÊî∂ÈõÜÂåªÁñó‰∏ì‰∏ö‰∫∫ÂëòÁöÑÂèçÈ¶à„ÄÇ',
        'web_interface': 'ÁΩëÁªúÁïåÈù¢',
        'web_interface_desc': 'ÂºÄÂèë‰∫ÜÁΩëÁªúÂ∫îÁî®Á®ãÂ∫èÔºå‰ΩøÂåªÁñó‰∏ì‰∏ö‰∫∫ÂëòÊó†ÈúÄÊäÄÊúØ‰∏ìÈïøÂç≥ÂèØ‰ΩøÁî®ËØ•ÊäÄÊúØ„ÄÇ',
        'testimonials': 'Áî®Êà∑ËØÑ‰ª∑',
        'team': 'Êàë‰ª¨ÁöÑÂõ¢Èòü',
        'lead_developer': 'È¶ñÂ∏≠ÂºÄÂèëËÄÖ',
        'lead_developer_desc': 'Ë¥üË¥£Ê†∏ÂøÉË∂ÖÂàÜËæ®ÁéáÁÆóÊ≥ïÂíåÊ®°ÂûãÊû∂ÊûÑËÆæËÆ°„ÄÇ',
        'ml_engineer': 'Êú∫Âô®Â≠¶‰π†Â∑•Á®ãÂ∏à',
        'ml_engineer_desc': '‰∏ìÈó®ËÆ≠ÁªÉÂíå‰ºòÂåñÁî®‰∫éÂåªÂ≠¶ÊàêÂÉèÂ∫îÁî®ÁöÑÊ∑±Â∫¶Â≠¶‰π†Ê®°Âûã„ÄÇ',
        'medical_advisor': 'ÂåªÂ≠¶È°æÈóÆ',
        'medical_advisor_desc': 'Êèê‰æõ‰∏¥Â∫ä‰∏ì‰∏öÁü•ËØÜÔºåÁ°Æ‰øùÊäÄÊúØÊª°Ë∂≥Áé∞ÂÆû‰∏ñÁïåÁöÑÂåªÁñóÈúÄÊ±Ç„ÄÇ',

        # Technology page specific
        'srcnn_title': 'Ë∂ÖÂàÜËæ®ÁéáÂç∑ÁßØÁ•ûÁªèÁΩëÁªú (SRCNN)',
        'srcnn_desc': 'SRCNNÊòØÊàë‰ª¨ÁöÑ‰∏ªË¶ÅÊ®°ÂûãÊû∂ÊûÑÔºåÊó®Âú®ÊúâÊïàÊèêÈ´òÂõæÂÉèÂàÜËæ®ÁéáÔºåÂêåÊó∂‰øùÁïôÈáçË¶ÅÁöÑÂåªÂ≠¶ÁªÜËäÇ„ÄÇËØ•ÁΩëÁªúÁî±‰∏â‰∏™‰∏ªË¶ÅÁªÑ‰ª∂ÁªÑÊàêÔºö',
        'srcnn_feature_extraction': 'ÁâπÂæÅÊèêÂèñÔºöÁ¨¨‰∏ÄÂ±Ç‰ªé‰ΩéÂàÜËæ®ÁéáËæìÂÖ•‰∏≠ÊèêÂèñÂõæÂÉèÂùóÂπ∂Â∞ÜÂÖ∂Ë°®Á§∫‰∏∫ÁâπÂæÅÂõæ„ÄÇ',
        'srcnn_nonlinear_mapping': 'ÈùûÁ∫øÊÄßÊò†Â∞ÑÔºö‰∏≠Èó¥Â±ÇÂ∞ÜËøô‰∫õÁâπÂæÅË°®Á§∫Êò†Â∞ÑÂà∞È´òÂàÜËæ®ÁéáÂõæÂÉèÂùóË°®Á§∫„ÄÇ',
        'srcnn_reconstruction': 'ÈáçÂª∫ÔºöÊúÄÂêé‰∏ÄÂ±ÇËÅöÂêàÈ¢ÑÊµãÁªìÊûúÔºåÁîüÊàêÈ´òÂàÜËæ®ÁéáËæìÂá∫„ÄÇ',
        'srcnn_diagram': 'SRCNNÊû∂ÊûÑÂõæ',

        'espcn_title': 'È´òÊïàÂ≠êÂÉèÁ¥†Âç∑ÁßØÁ•ûÁªèÁΩëÁªú (ESPCN)',
        'espcn_desc': 'ESPCNÊòØ‰∏ÄÁßçÊõø‰ª£Êû∂ÊûÑÔºå‰ΩøÁî®Â≠êÂÉèÁ¥†Âç∑ÁßØËøõË°åÈ´òÊïà‰∏äÈááÊ†∑„ÄÇËØ•Ê®°ÂûãÂú®‰ΩéÂàÜËæ®ÁéáÁ©∫Èó¥Â§ÑÁêÜÂõæÂÉèÔºå‰ªÖÂú®ÊúÄÂêéËøõË°å‰∏äÈááÊ†∑Ôºå‰ΩøÂÖ∂ËÆ°ÁÆóÊïàÁéáÈ´ò„ÄÇ',
        'espcn_diagram': 'ESPCNÊû∂ÊûÑÂõæ',

        'edsr_title': 'Â¢ûÂº∫ÂûãÊ∑±Â∫¶Ë∂ÖÂàÜËæ®ÁéáÁΩëÁªú (EDSR)',
        'edsr_desc': 'EDSRÊòØÊàë‰ª¨ÊúÄÂÖàËøõÁöÑÊ®°ÂûãÔºå‰∏ì‰∏∫È´òË¥®ÈáèË∂ÖÂàÜËæ®ÁéáËÆæËÆ°„ÄÇÂÆÉ‰ªé‰º†ÁªüÊÆãÂ∑ÆÁΩëÁªú‰∏≠ÁßªÈô§‰∫Ü‰∏çÂøÖË¶ÅÁöÑÊ®°ÂùóÔºåÊâ©Â±ï‰∫ÜÊ®°ÂûãÂ§ßÂ∞èÔºåÂêåÊó∂Á®≥ÂÆö‰∫ÜËÆ≠ÁªÉËøáÁ®ã„ÄÇ',
        'edsr_diagram': 'EDSRÊû∂ÊûÑÂõæ',
        'edsr_effective': 'Ëøô‰∏™Ê®°ÂûãÂØπ‰∫éÁªÜËäÇÂØπËØäÊñ≠Ëá≥ÂÖ≥ÈáçË¶ÅÁöÑÂ§çÊùÇÂåªÂ≠¶ÂõæÂÉèÁâπÂà´ÊúâÊïà„ÄÇ',

        'psnr_metric': 'PSNR',
        'psnr_metric_desc': 'Â≥∞ÂÄº‰ø°Âô™ÊØîË°°Èáè‰ø°Âè∑ÁöÑÊúÄÂ§ßÂèØËÉΩÂäüÁéá‰∏éÂπ≤Êâ∞Âô™Â£∞ÂäüÁéá‰πãÈó¥ÁöÑÊØîÁéá',
        'psnr_formula_desc': 'ÂÖ∂‰∏≠MAX‚ÇÅÊòØÊúÄÂ§ßÂÉèÁ¥†ÂÄºÔºà8‰ΩçÂõæÂÉè‰∏∫255ÔºâÔºåMSEÊòØÂéüÂßãÂõæÂÉèÂíåÂ§ÑÁêÜÂêéÂõæÂÉè‰πãÈó¥ÁöÑÂùáÊñπËØØÂ∑Æ„ÄÇ',
        'psnr_typical_values': 'ÂåªÂ≠¶ÂõæÂÉèÁöÑÂÖ∏ÂûãÂÄºËåÉÂõ¥‰∏∫25-45 dBÔºåÂÄºË∂äÈ´òË°®Á§∫Ë¥®ÈáèË∂äÂ•Ω„ÄÇ',

        'ssim_metric': 'SSIM',
        'ssim_metric_desc': 'ÁªìÊûÑÁõ∏‰ººÊÄßÊåáÊï∞Âü∫‰∫éÁªìÊûÑ‰ø°ÊÅØ„ÄÅ‰∫ÆÂ∫¶ÂíåÂØπÊØîÂ∫¶Ë°°Èáè‰∏§‰∏™ÂõæÂÉè‰πãÈó¥ÁöÑÁõ∏‰ººÊÄß„ÄÇÂÄºËåÉÂõ¥‰ªé-1Âà∞1Ôºå1Ë°®Á§∫ÂÆåÂÖ®Áõ∏‰ºº„ÄÇ',
        'ssim_perception': '‰∏éPSNR‰∏çÂêåÔºåSSIMËÄÉËôë‰∫Ü‰∫∫Á±ªËßÜËßâÊÑüÁü•Ôºå‰ΩøÂÖ∂‰∏éÊÑüÁü•ÂõæÂÉèË¥®ÈáèÊõ¥Âä†‰∏ÄËá¥„ÄÇ',
        'ssim_typical_values': 'ÂØπ‰∫éÂåªÂ≠¶ÂõæÂÉèÔºåSSIMÂÄºÈ´ò‰∫é0.85ÈÄöÂ∏∏Ë°®Á§∫ËâØÂ•ΩÁöÑË¥®Èáè‰øùÂ≠ò„ÄÇ',

        'metrics_auto_calc': 'Êàë‰ª¨ÁöÑÂ∫îÁî®Á®ãÂ∫èËá™Âä®ËÆ°ÁÆóÂπ∂ÊòæÁ§∫ÊØè‰∏™Â§ÑÁêÜÂõæÂÉèÁöÑËøô‰∫õÊåáÊ†áÔºå‰ΩøÊÇ®ËÉΩÂ§üÂÆ¢ËßÇÊØîËæÉ‰∏çÂêåÁöÑË∂ÖÂàÜËæ®ÁéáÊñπÊ≥ï„ÄÇ',

        'dataset_title': 'Êï∞ÊçÆÈõÜ',
        'dataset_desc': 'Ê®°ÂûãÂú®Â§öÊ†∑ÂåñÁöÑÂåªÂ≠¶ÂõæÂÉèÊï∞ÊçÆÈõÜ‰∏äËÆ≠ÁªÉÔºåÂåÖÊã¨Ôºö',
        'dataset_xray': 'XÂ∞ÑÁ∫øÔºàËÉ∏ÈÉ®„ÄÅÈ™®È™º„ÄÅÁâôÁßëÔºâ',
        'dataset_mri': 'MRIÊâ´ÊèèÔºàÂ§ßËÑë„ÄÅËÑäÊ§é„ÄÅÂÖ≥ËäÇÔºâ',
        'dataset_ct': 'CTÊâ´ÊèèÔºàÂêÑÁßçË∫´‰ΩìÂå∫ÂüüÔºâ',
        'dataset_ultrasound': 'Ë∂ÖÂ£∞Ê≥¢ÂõæÂÉè',

        'training_methodology': 'ËÆ≠ÁªÉÊñπÊ≥ï',
        'training_methodology_desc': 'Êàë‰ª¨ÈááÁî®Âá†ÁßçÂÖàËøõÊäÄÊúØÊù•‰ºòÂåñÊ®°ÂûãÊÄßËÉΩÔºö',
        'mixed_precision': 'Ê∑∑ÂêàÁ≤æÂ∫¶ËÆ≠ÁªÉÔºöÂú®‰øùÊåÅÂáÜÁ°ÆÊÄßÁöÑÂêåÊó∂Âä†ÈÄüËÆ≠ÁªÉ',
        'learning_rate': 'Â≠¶‰π†ÁéáË∞ÉÂ∫¶ÔºöËá™ÈÄÇÂ∫îÂ≠¶‰π†Áéá‰ª•Ëé∑ÂæóÊúÄ‰Ω≥Êî∂Êïõ',
        'early_stopping': 'Êó©ÂÅúÔºöÈÄöËøáÁõëÊéßÈ™åËØÅÊÄßËÉΩÈò≤Ê≠¢ËøáÊãüÂêà',
        'gradient_clipping': 'Ê¢ØÂ∫¶Ë£ÅÂâ™ÔºöÈÄöËøáÈò≤Ê≠¢Ê¢ØÂ∫¶ÁàÜÁÇ∏Á®≥ÂÆöËÆ≠ÁªÉ',
        'data_augmentation': 'Êï∞ÊçÆÂ¢ûÂº∫ÔºöÈÄöËøáÂêàÊàêÂèòÂåñÂ¢ûÂº∫Ê®°ÂûãÊ≥õÂåñËÉΩÂäõ',

        'clinical_applications': '‰∏¥Â∫äÂ∫îÁî®',
        'clinical_applications_desc': 'Êàë‰ª¨ÁöÑË∂ÖÂàÜËæ®ÁéáÊäÄÊúØÂú®‰∏¥Â∫äÁéØÂ¢É‰∏≠ÊúâÂá†‰∏™ÈáçË¶ÅÂ∫îÁî®Ôºö',
        'legacy_enhancement': 'ÊóßËÆæÂ§áÂ¢ûÂº∫',
        'legacy_enhancement_desc': 'ÊèêÈ´òÊóßÂåªÂ≠¶ÊàêÂÉèËÆæÂ§áÁöÑÂõæÂÉèË¥®ÈáèÔºåÂª∂ÈïøÂÖ∂‰ΩøÁî®ÂØøÂëΩÔºåÊó†ÈúÄÁ°¨‰ª∂ÂçáÁ∫ßÂç≥ÂèØÊèêÈ´òËØäÊñ≠ËÉΩÂäõ„ÄÇ',
        'detail_enhancement': 'ÁªÜËäÇÂ¢ûÂº∫',
        'detail_enhancement_desc': 'Â¢ûÂº∫ÂåªÂ≠¶ÂõæÂÉè‰∏≠ÂØπÂáÜÁ°ÆËØäÊñ≠ÂèØËÉΩËá≥ÂÖ≥ÈáçË¶ÅÁöÑÁ≤æÁªÜÁªÜËäÇÔºåÂ¶ÇÂ∞èÁóÖÂèò„ÄÅÈ™®ÊäòÁ∫øÊàñÁªÑÁªáÂºÇÂ∏∏„ÄÇ',
        'archive_restoration': 'Ê°£Ê°à‰øÆÂ§ç',
        'archive_restoration_desc': 'ÊèêÈ´òÂèØËÉΩÈöèÊó∂Èó¥ÈÄÄÂåñÊàñÊúÄÂàù‰ª•ËæÉ‰ΩéÂàÜËæ®ÁéáÊçïËé∑ÁöÑÂ≠òÊ°£ÂåªÂ≠¶ÂõæÂÉèÁöÑË¥®Èáè„ÄÇ',
        'telemedicine': 'ËøúÁ®ãÂåªÁñóÊîØÊåÅ',
        'telemedicine_desc': 'ÊèêÈ´òËøúÁ®ãÂåªÁñóÂ∫îÁî®‰∏≠‰º†ËæìÂõæÂÉèÁöÑË¥®ÈáèÔºåÁ°Æ‰øùËøúÁ®ã‰∏ìÂÆ∂ËÉΩÂ§üÂÅöÂá∫ÂáÜÁ°ÆËØÑ‰º∞„ÄÇ',
        'xray_enhancement': 'Á§∫‰æãÔºöXÂ∞ÑÁ∫øÂ¢ûÂº∫',
        'original': 'ÂéüÂßãÂõæÂÉè',
        'enhanced': 'Â¢ûÂº∫ÂõæÂÉè',

        # About page specific
        'ongoing_development': 'ÊåÅÁª≠ÂºÄÂèë',
        'ongoing_development_desc': 'ÁªßÁª≠ÊîπËøõÊ®°ÂûãÊÄßËÉΩÔºåÊâ©Â±ïÊîØÊåÅÁöÑÂõæÂÉèÁ±ªÂûãÔºåÂπ∂Ê†πÊçÆÁî®Êà∑ÂèçÈ¶àÂ¢ûÂº∫Áî®Êà∑ÁïåÈù¢„ÄÇ',
        'january_2023': '2023Âπ¥1Êúà',
        'march_2023': '2023Âπ¥3Êúà',
        'june_2023': '2023Âπ¥6Êúà',
        'october_2023': '2023Âπ¥10Êúà',
        'january_2024': '2024Âπ¥1Êúà',
        'present': 'Áé∞Âú®',

        'testimonial1': '"ËøôÈ°πÊäÄÊúØÊòæËëóÊèêÈ´ò‰∫ÜÊàë‰ª¨ÂàÜÊûêÊóßXÂ∞ÑÁ∫øÂõæÂÉè‰∏≠ÁªÜÂæÆÁªÜËäÇÁöÑËÉΩÂäõ„ÄÇËøôÂ∞±ÂÉèÂú®‰∏çÊõ¥Êç¢ËÆæÂ§áÁöÑÊÉÖÂÜµ‰∏ãËé∑Âæó‰∫ÜÁ°¨‰ª∂ÂçáÁ∫ß„ÄÇ"',
        'testimonial1_author': '‚Äî Sarah JohnsonÂåªÁîüÔºåÊîæÂ∞ÑÁßëÂåªÂ∏à',
        'testimonial2': '"Êàë‰ª¨‰∏ÄÁõ¥Âú®‰ΩøÁî®Ëøô‰∏™Â∑•ÂÖ∑Â¢ûÂº∫Ë∂ÖÂ£∞Ê≥¢ÂõæÂÉèÔºåÁªìÊûúÈùûÂ∏∏ÊòæËëó„ÄÇÂ¢ûÂº∫ÁöÑÊ∏ÖÊô∞Â∫¶Â∏ÆÂä©Êàë‰ª¨ÂÅöÂá∫Êõ¥Êúâ‰ø°ÂøÉÁöÑËØäÊñ≠ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÊ°à‰æã‰∏≠„ÄÇ"',
        'testimonial2_author': '‚Äî Michael ChenÂåªÁîüÔºåË∂ÖÂ£∞Ê£ÄÊü•Â∏à',
        'testimonial3': '"‰Ωú‰∏∫ËµÑÊ∫êÊúâÈôêÁöÑÂÜúÊùëÂåªÁñóÊèê‰æõËÄÖÔºåËøôÈ°πÊäÄÊúØÈùûÂ∏∏ÂÆùË¥µ„ÄÇÂÆÉÂ∏ÆÂä©Êàë‰ª¨‰ªéÁé∞ÊúâÁöÑÊàêÂÉèËÆæÂ§á‰∏≠Ëé∑ÂæóÊõ¥Â§öÁöÑËØäÊñ≠‰ª∑ÂÄº„ÄÇ"',
        'testimonial3_author': '‚Äî Robert PatelÂåªÁîüÔºåÂÜúÊùëÂÅ•Â∫∑ËØäÊâÄ‰∏ª‰ªª',

        # Footer
        'footer_copyright': '¬© 2025 ÂåªÂ≠¶Ë∂ÖÂàÜËæ®ÁéáÈ°πÁõÆ',
        'footer_powered': 'Áî±PyTorchÂíåFlaskÊèê‰æõÊîØÊåÅ'
    }
}

def get_text(key, lang='en', *args):
    """
    Get translated text for the given key and language.

    Args:
        key: The translation key
        lang: Language code ('en' or 'zh')
        *args: Format arguments if the text contains placeholders

    Returns:
        Translated text
    """
    if lang not in translations:
        lang = 'en'  # Fallback to English

    text = translations[lang].get(key, translations['en'].get(key, key))

    if args:
        try:
            return text.format(*args)
        except:
            return text

    return text
